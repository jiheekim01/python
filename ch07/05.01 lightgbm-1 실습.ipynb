{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "print(lightgbm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.7\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "print(hyperopt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperopt : ML 모델의 하이퍼파라미터의 최적화(best parameter 찾기) 할때 사용\n",
    "# 1. 공간(space) 설정 : best parameter가 있을 것 같은 범위 지정\n",
    "# 2. 평가 지표 설정 : 목적 함수 설정 (사용자가 선언) 보통 오차율\n",
    "# 3. 최적화 알고리즘(search), TPE(Tree-structured Parzen Estimator) <- 최적의 값을 찾는 알고리즘\n",
    "# 베이지안 기법(Bayesian Optimization) 중 하나\n",
    "# 기존의 그리드 탐색(Grid Search)이나 랜덤 탐색(Random Search)보다 더 효율적\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TPE의 주요 목적\n",
    "\n",
    "- TPE의 목적은 **하이퍼파라미터 공간**에서 최적의 값을 찾는 것입니다. 여러 번의 실험을 통해 최적화가 이루어지며, 기존의 **그리드 탐색**(Grid Search)이나 **랜덤 탐색**(Random Search)보다 더 효율적입니다.\n",
    "\n",
    "#### TPE의 작동 원리\n",
    "- TPE는 **확률적 모델**을 기반으로 하여, 하이퍼파라미터 공간을 효율적으로 탐색합니다. TPE는 두 가지 분포를 모델링하는 방식으로 작동합니다:\n",
    "    - **좋은 파라미터 분포** (목표 함수가 잘 수행된 파라미터들)\n",
    "    - **나쁜 파라미터 분포** (목표 함수가 잘 수행되지 않은 파라미터들)\n",
    "\n",
    "- TPE는 주어진 하이퍼파라미터 공간에서 \"좋은\" 파라미터를 더 많이 샘플링하려고 합니다. 모델은 하이퍼파라미터 값이 더 잘 성능을 낼 가능성이 있는 부분을 선택하여 점차 최적의 하이퍼파라미터를 찾습니다.\n",
    "\n",
    "#### TPE의 특징\n",
    "- **확률적 접근**: TPE는 각 하이퍼파라미터 값이 주는 성능을 확률 모델로 추정합니다. 이를 통해 더 나은 파라미터 조합을 효율적으로 찾을 수 있습니다.\n",
    "- **대체로 효율적**: 랜덤 탐색보다 빠르고 효율적으로 최적의 하이퍼파라미터를 찾을 수 있습니다.\n",
    "- **다양한 최적화 문제에 적용 가능**: 머신러닝 모델의 하이퍼파라미터 튜닝뿐만 아니라, 다른 최적화 문제에도 적용할 수 있습니다.\n",
    "\n",
    "#### TPE 알고리즘의 작동 방식\n",
    "\n",
    "- TPE는 다음과 같은 방식으로 작동합니다:\n",
    "    - **모델 초기화**: 파라미터 공간을 정의하고, 해당 공간에서 샘플을 랜덤하게 추출하여 목표 함수를 평가합니다.\n",
    "    - **확률적 모델 학습**: TPE는 이전 실험 결과를 바탕으로 **좋은 파라미터 분포**와 **나쁜 파라미터 분포**를 학습합니다. 이때, 좋은 파라미터는 목표 함수에서 높은 성능을 보인 값들입니다.\n",
    "    - **새로운 파라미터 샘플링**: 학습된 분포를 바탕으로 새로운 파라미터를 샘플링하고, 이 샘플에 대해 목표 함수를 다시 평가합니다.\n",
    "    - **반복**: 이 과정을 반복하면서 점차 좋은 하이퍼파라미터 조합을 찾아냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search는 순차적으로 대입해서 찾기 때문에 느리다\n",
    "# tpe는 공간(구간 or 범위)를 정한 다음 좋은 분포와 나쁜 분포로 구분 짓고\n",
    "# 나쁜 분포는 버리고 좋은 분포에서만 반복\n",
    "# 더 빠르게 최적화가 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.pyll.base.Apply at 0x23366cb2ce0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "# 바깥 'x' 는 key, 튜플 안에 있는 'x' 는 접근을 위한 목적 함수\n",
    "search_space={'x':hp.quniform('x',-10,10,1),\n",
    "              'y':hp.quniform('y',-15,15,1)\n",
    "              }\n",
    "search_space.get('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적 함수를 선언, 변숫값과 변수 검색 공간을 가지는 딕셔너리\n",
    "def objective_func(search_space):\n",
    "    x=search_space['x']\n",
    "    y=search_space['y']\n",
    "    retval=x**2 - 20*y\n",
    "    \n",
    "    return retval\n",
    "\n",
    "# retval = return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 454.47trial/s, best loss: -224.0]\n",
      "best :{'x': np.float64(-4.0), 'y': np.float64(12.0)}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin,tpe,Trials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 입력 결과값을 저장한 Trials 객체값 생성\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변수값을 5번의 입력값 시도(max_evals=5)로 찾아냄\n",
    "# 목적 함수, 공간을 fmin()에 넣어서 최소가 되는 x,y를 찾는다\n",
    "best_01=fmin(fn=objective_func,\n",
    "             space=search_space,\n",
    "             algo=tpe.suggest,\n",
    "             max_evals=5,\n",
    "             trials=trial_val,\n",
    "             rstate=np.random.default_rng(seed=0)\n",
    "             )\n",
    "\n",
    "print(f'best :{best_01}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best 최솟값: {'x': np.float64(-4.0), 'y': np.float64(12.0)}\n"
     ]
    }
   ],
   "source": [
    "print(f'best 최솟값: {best_01}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-224.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x 가 -4 이고, y 가 12 일때 \n",
    "((-4.0)**2) - (20 * 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
